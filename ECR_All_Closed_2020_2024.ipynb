{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlePyF1CMPbRR2yCGsaUTh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaksbhat/Colab_JupyterNotebooks/blob/main/ECR_All_Closed_2020_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H26XXv1G1Ew4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ECR_All_Closed_2020_2024"
      ],
      "metadata": {
        "id": "AmM2mpvQAMle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##data"
      ],
      "metadata": {
        "id": "30ZmtouZmTTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_og = pd.read_excel(\"/content/ECR_All_Closed_2020_2024.xlsx\")\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "0QyG0HhsAQlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "88de5037-b8f9-4ace-a2fa-ac26cb47c852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ECR_All_Closed_2020_2024.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-afe9793060fa>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_og\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/ECR_All_Closed_2020_2024.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ECR_All_Closed_2020_2024.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_og.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "vbDs4iZzYHs6",
        "outputId": "460c2661-7a48-4294-bf83-0e78d1f8555a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_og' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3e42f698068a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_og\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_og' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_og[['ECR_CODE', 'SOURCE OF CHANGE', 'ECR_CREATION_DATE', 'REASON_DESC', 'CHANGE_TYPE','COSTING_PROJECTS','MATERIAL_CATEGORY','CHANGE_CATEGORY','CHANGE DESCRIPTION','IMPACTEDITEM', 'IMPACTED ITEM DESCRIPTION','FUNCTION','DIVISION','ORGANIZATION NAME','AGING','SUB_PL']]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "Wv6wycRTAocO",
        "outputId": "98dce4c5-8bdb-4fa0-b626-159051449fea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_og' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6f0fcc44c8de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_og\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ECR_CODE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SOURCE OF CHANGE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ECR_CREATION_DATE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'REASON_DESC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CHANGE_TYPE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'COSTING_PROJECTS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MATERIAL_CATEGORY'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CHANGE_CATEGORY'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CHANGE DESCRIPTION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'IMPACTEDITEM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IMPACTED ITEM DESCRIPTION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'FUNCTION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DIVISION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ORGANIZATION NAME'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'AGING'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SUB_PL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_og' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_FFF= df[(df['CHANGE_TYPE'] == 'FFF&P ONLY')]\n",
        "df_CIS_FFF = df[(df['CHANGE_TYPE'] == 'CIS/CIS+FFF&P')]"
      ],
      "metadata": {
        "id": "X528kDjQGygd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_FFF.head(2)"
      ],
      "metadata": {
        "id": "NtKZLtcgHKtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_CIS_FFF.head(2)"
      ],
      "metadata": {
        "id": "QIAXnrDqHqu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##graphs"
      ],
      "metadata": {
        "id": "tnt9GiLqCT8P"
      }
    },
    {
      "source": [
        "# FUNCTION\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df.groupby('FUNCTION').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "plt.title(\"Function vs Count\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Function\")"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "tsN8lJ7JBLHu"
      }
    },
    {
      "source": [
        "# SOURCE OF CHANGE\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "df.groupby('SOURCE OF CHANGE').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "plt.title(\"Source of Change vs Count\")\n",
        "plt.xlabel(\"Count\")\n",
        "plt.ylabel(\"Source of Change\")"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "wiLjK4u_BDDg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZcMKlcNQCXOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ECR_CODE\n",
        "Each ECR_CODE has multiple COSTING_PROJECTS\n",
        "\n",
        "\n",
        "So, ECR_CODE is grouped along with COSTING_PROJECTS(Job No.)\n",
        "\n",
        "\n",
        "Now ECR_CODE can be used as PK\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLulZFQXCo7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_cols(df, colA, colB):\n",
        "    grouped_df = df.groupby(colA)[colB].agg(list).reset_index()\n",
        "    grouped_df.rename(columns={colB: colB + '_new_col'}, inplace=True)\n",
        "    df = pd.merge(df, grouped_df, on=colA, how='left')\n",
        "    df.drop(colB, axis=1, inplace=True)\n",
        "    return df"
      ],
      "metadata": {
        "id": "SpMQj4ChCo7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=group_cols(df,'ECR_CODE','COSTING_PROJECTS')"
      ],
      "metadata": {
        "id": "OpjjeUerCo7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change type to string\n",
        "# remove brackets\n",
        "# drop duplicate so that ECR_CODE can act as PK\n",
        "df['COSTING_PROJECTS_new_col']=df['COSTING_PROJECTS_new_col'].astype(str)\n",
        "df['COSTING_PROJECTS_new_col'] = df['COSTING_PROJECTS_new_col'].str.replace(r'[\\[\\]\\']', '', regex=True)\n"
      ],
      "metadata": {
        "id": "DooXWswyCo7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "qVVJp60ILxdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(50)"
      ],
      "metadata": {
        "id": "Ycz4aGhwaN-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "erfOKJ3fezql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to sort each cell\n",
        "def sort_costing_projects(cell):\n",
        "    # Ensure the cell is a string before processing\n",
        "    if isinstance(cell, list):\n",
        "        cell = ', '.join(cell)  # Convert list to string\n",
        "    # Split, strip whitespace, sort, and rejoin\n",
        "    sorted_items = sorted(item.strip() for item in cell.split(','))\n",
        "    return ', '.join(sorted_items)\n"
      ],
      "metadata": {
        "id": "akSdyC2JeVBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to each cell in the specified column\n",
        "df['COSTING_PROJECTS_new_col'] = df['COSTING_PROJECTS_new_col'].apply(sort_costing_projects)\n",
        "\n"
      ],
      "metadata": {
        "id": "QDPbXUdprll4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Cxm9TPshtV9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 most mentioned string in df[COSTING_PROJECTS_new_col]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def top_mentioned_strings(df, column, top_n):\n",
        "\n",
        "    all_strings = []\n",
        "    for value in df[column]:\n",
        "        if isinstance(value, str):  # Check if the value is a string\n",
        "            strings = value.split(',')\n",
        "            all_strings.extend(strings)\n",
        "    string_counts = Counter(all_strings)\n",
        "    top_strings = string_counts.most_common(top_n)\n",
        "    return top_strings\n",
        "\n"
      ],
      "metadata": {
        "id": "H4FiZSljtubT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "top_10_strings = top_mentioned_strings(df, 'COSTING_PROJECTS_new_col', 10)\n",
        "top_10_strings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "9hA3zyCDuTDu",
        "outputId": "31ddd0a8-e55b-45bb-db56-c6d0b83d3e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c73cc1ce5bbc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_10_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_mentioned_strings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'COSTING_PROJECTS_new_col'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_10_strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot above top_10_strings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming top_10_strings is a list of tuples (string, count)\n",
        "strings, counts = zip(*top_10_strings)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(strings, counts,color='pink')\n",
        "plt.xlabel(\"COSTING_PROJECTS\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Top 10 Most Mentioned COSTING_PROJECTS\")\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B7QBsbvFwSDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##modified df  |  made costing_projects as pk and has been grouped togather"
      ],
      "metadata": {
        "id": "qhIGEnqDetKL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4kZMcFPsRMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: if  df[COSTING_PROJECTS_new_col] value is same then merge those rows\n",
        "\n",
        "def merge_rows_with_same_costing_projects(df):\n",
        "    # Group by 'COSTING_PROJECTS_new_col' and aggregate other columns\n",
        "    grouped = df.groupby('COSTING_PROJECTS_new_col').agg({\n",
        "        'ECR_CODE': lambda x: ','.join(x.astype(str)),  # Combine ECR codes\n",
        "        'CHANGE DESCRIPTION': lambda x: ','.join(x.astype(str)),\n",
        "        'IMPACTEDITEM': lambda x: ','.join(x.astype(str)), #Combine IMPACTEDITEM values\n",
        "\n",
        "\n",
        "    }).reset_index()\n",
        "\n",
        "    return grouped\n",
        "\n",
        "df_merged = merge_rows_with_same_costing_projects(df)\n",
        "df_merged"
      ],
      "metadata": {
        "id": "wFNPrg55YaKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.shape"
      ],
      "metadata": {
        "id": "5svcOl8UY_Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['ECR_CODE'].value_counts()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tKGv6Wl9LONn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ECR-550831\thas 2 values coz IMPACTED ITEM DESCRIPTION\tis differently described"
      ],
      "metadata": {
        "id": "YlzDkQ78Co7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "Method to find all rows which has more than 2 values in a col\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "4vvYDj0sCo7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to find all rows which has more than 2 values in a col. example [1908315, 1703775]\n",
        "\n",
        "def find_rows_with_multiple_values(df, colA, value):\n",
        "\n",
        "    result_df = df[df[colA].str.split(',').str.len() > value]\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "lYwbxHU8Co7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_multiple_costingprojects=find_rows_with_multiple_values(df,'COSTING_PROJECTS_new_col',1)"
      ],
      "metadata": {
        "id": "SqE9KoBeCo7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_multiple_costingprojects.head()"
      ],
      "metadata": {
        "id": "pkLzI8PuMS-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#grouping costing_projects to ECR_code\n",
        "\n"
      ],
      "metadata": {
        "id": "d1sORoZEVkxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "otUPJMgCVkvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R5O5NDFjVkrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SOURCE OF CHANGE\n",
        "\n",
        "has 5 unique values.\n",
        "\n",
        "So, label encode these"
      ],
      "metadata": {
        "id": "EGG5D2iLCo7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "vMfTJ-Xx6AO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot graph on df['SOURCE OF CHANGE']\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['SOURCE OF CHANGE'].value_counts().plot(kind='barh')\n",
        "plt.ylabel('Source of Change')\n",
        "plt.xlabel('Count')\n",
        "plt.title('Distribution of Source of Change')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "brv72Asc4MFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SOURCE OF CHANGE'].unique()"
      ],
      "metadata": {
        "id": "w2PylYrdCo7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##REASON_DESC\n",
        "\n",
        "has unique values\n",
        "\n",
        "So, label encode these"
      ],
      "metadata": {
        "id": "6aZwIbLcCo7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['REASON_DESC'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "frpBMLOkf2Pq",
        "outputId": "323ec865-1440-46b1-eea5-58953d66c4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-10bc0d0c52e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'REASON_DESC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 6))\n",
        "df['REASON_DESC'].value_counts().plot(kind='barh')\n",
        "plt.ylabel('REASON_DESC')\n",
        "plt.xlabel('Count')\n",
        "plt.title('Distribution of REASON_DESC')\n",
        "plt.gca().spines[['top', 'right']].set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ix8MrwMD-VnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: group REASON_DESC and MATERIAL_CATEGORY and find top 10 MATERIAL_CATEGORY for each REASON_DESC\n",
        "\n",
        "# Group by 'REASON_DESC' and 'MATERIAL_CATEGORY', then get the top 10 'MATERIAL_CATEGORY' for each 'REASON_DESC'\n",
        "top_10_materials_for_reason = df.groupby('REASON_DESC')['MATERIAL_CATEGORY'].value_counts().groupby(level=0).head(5)\n",
        "\n",
        "top_10_materials_for_reason"
      ],
      "metadata": {
        "id": "Bs-5DCNl_LDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming top_10_materials_for_reason is already defined as in your provided code\n",
        "# Iterate through each unique REASON_DESC\n",
        "for reason in top_10_materials_for_reason.index.get_level_values(0).unique():\n",
        "    # Get the top 10 materials for the current reason\n",
        "    reason_data = top_10_materials_for_reason[reason]\n",
        "    # Create the pie chart\n",
        "    plt.figure(figsize=(18, 16))  # Adjust figure size as needed\n",
        "    plt.pie(reason_data, autopct='%1.1f%%', startangle=90, explode=[0.05] * len(reason_data)) #Added autopct for percentage values\n",
        "    plt.title(f'Reason: {reason}')\n",
        "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "    plt.legend(reason_data.index, loc='upper left', bbox_to_anchor=(1, 1)) #legend only\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YKU044NDBJ2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['REASON_DESC'].unique()"
      ],
      "metadata": {
        "id": "I-GF61kXCo7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHANGE_CATEGORY\n",
        "\n",
        "eventhough it has unique values, its in mixtured form\n",
        "apply multilabel binarizer\n",
        "\n",
        "here u can ignore 'DOCUMENT' col as they cause no major impacts"
      ],
      "metadata": {
        "id": "wUYdoZpXCo7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['CHANGE_CATEGORY'].unique()"
      ],
      "metadata": {
        "id": "nCzuKV4RCo7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seperate if df['CHANGE_CATEGORY']=='DOCUMENT'"
      ],
      "metadata": {
        "id": "HYsfhgqiCo7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_document=df[df['CHANGE_CATEGORY']=='DOCUMENT']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df=df[df['CHANGE_CATEGORY']!='DOCUMENT']"
      ],
      "metadata": {
        "id": "julH9ok_Co7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_document.head()     #will have only documents"
      ],
      "metadata": {
        "id": "xG10y_TJCo7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPmttOB4Co7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_6y4LyZFCo7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CHANGE_CATEGORY']=df['CHANGE_CATEGORY'].astype(str)"
      ],
      "metadata": {
        "id": "YVPmR93lJhto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_change_category_words(text):\n",
        "    words = text.lower().split(',')\n",
        "    return Counter(words)\n",
        "\n",
        "change_category_word_counts = df['CHANGE_CATEGORY'].apply(count_change_category_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_change_category_word_counts = Counter()\n",
        "for counts in change_category_word_counts:\n",
        "    total_change_category_word_counts.update(counts)\n",
        "\n",
        "total_change_category_word_counts"
      ],
      "metadata": {
        "id": "of3Dp68wJJBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TeX8-35_J7mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_change_category(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_change_category_word_counts[word]"
      ],
      "metadata": {
        "id": "GGj8MZdjKBUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_change_category(\"move component\")"
      ],
      "metadata": {
        "id": "7LP6CenoKBUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_in_change_category(word, change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['CHANGE_CATEGORY'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','MATERIAL_CATEGORY']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "uRQj5HglKBUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word_in_change_category(\"move component\", \"FFF&P ONLY\")"
      ],
      "metadata": {
        "id": "pjK2_ItJKBUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MATERIAL_CATEGORY\n",
        "\n",
        "has unique values\n",
        "\n",
        "So, label encode these"
      ],
      "metadata": {
        "id": "kHrn0x8ACo7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: for each of df[COSTING_PROJECTS] find top MATERIAL_CATEGORY value\n",
        "\n",
        "def get_top_material_category(df):\n",
        "\n",
        "\n",
        "    # Group by 'COSTING_PROJECTS' and get the mode of 'MATERIAL_CATEGORY'\n",
        "    top_material_categories = df.groupby('COSTING_PROJECTS_new_col')['MATERIAL_CATEGORY'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown').reset_index()\n",
        "    return top_material_categories\n",
        "\n",
        "\n",
        "# Example usage (assuming your DataFrame is named 'df'):\n",
        "top_categories_df = get_top_material_category(df)\n",
        "\n",
        "top_categories_df"
      ],
      "metadata": {
        "id": "gxDGS8sTyAdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot pie graph for top 10 MATERIAL_CATEGORY for above top_categories_d\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'top_categories_df' is already defined as in your provided code.\n",
        "top_10_materials = top_categories_df['MATERIAL_CATEGORY'].value_counts().nlargest(5)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.pie(top_10_materials, labels=top_10_materials.index, autopct='%1.1f%%', startangle=90)\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.title(\"Top 5 material categories\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NMsaDsCUytoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: top 5 MATERIAL_CATEGORY values\n",
        "\n",
        "# Assuming df is your DataFrame as defined in the provided code.\n",
        "top_5_materials = df['MATERIAL_CATEGORY'].value_counts().nlargest(5)\n",
        "top_5_materials"
      ],
      "metadata": {
        "id": "aA7EH-zRHkcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: plot graph for top_5_materials\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming top_5_materials is already defined as in your provided code.\n",
        "plt.figure(figsize=(8, 6))\n",
        "top_5_materials.plot(kind='bar', color='skyblue')\n",
        "plt.title('Top 5 Material Categories')\n",
        "plt.xlabel('Material Category')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iqzd6selH5Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MATERIAL_CATEGORY'].value_counts()"
      ],
      "metadata": {
        "id": "PZRt1a9JHbX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MATERIAL_CATEGORY']=df['MATERIAL_CATEGORY'].astype(str)"
      ],
      "metadata": {
        "id": "mkQob7EnOxpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_material_words(text):\n",
        "    words = text.lower().split(',')\n",
        "    return Counter(words)\n",
        "\n",
        "material_category_word_counts = df['MATERIAL_CATEGORY'].apply(count_material_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_material_category_word_counts = Counter()\n",
        "for counts in material_category_word_counts:\n",
        "    total_material_category_word_counts.update(counts)\n",
        "\n",
        "total_material_category_word_counts"
      ],
      "metadata": {
        "id": "GEvAUka78AXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_material_category(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_material_category_word_counts[word]"
      ],
      "metadata": {
        "id": "xBSP6OjANonD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_material_category(\"gearbox\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "vuIeLP9tO4Lw",
        "outputId": "1b8b0da2-97e2-421d-a6e8-66da53d367f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'total_material_category_word_counts' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-14b39c20d2f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_material_category\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gearbox\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-e4e6589a978b>\u001b[0m in \u001b[0;36msearch_material_category\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_material_category_word_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'total_material_category_word_counts' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_in_material_category(word, change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['MATERIAL_CATEGORY'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','MATERIAL_CATEGORY']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "Nq8pC_FZN079"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word_in_material_category(\"gearbox\", \"FFF&P ONLY\")"
      ],
      "metadata": {
        "id": "VOEix_RYOF5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CHANGE DESCRIPTION\n",
        "\n",
        "convert to english\n",
        "\n",
        "perform text preprocessing\n",
        "\n",
        "extract doc if mentioned in a new col"
      ],
      "metadata": {
        "id": "24FBJ7_aCo7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "wOuVjQSB-ENV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "metadata": {
        "id": "lOXXY9wLt51c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Upixwy2dwETm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['CHANGE DESCRIPTION'] = df['CHANGE DESCRIPTION'].astype(str)"
      ],
      "metadata": {
        "id": "ZqMZYxCOzJsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from googletrans import Translator\n",
        "\n",
        "# Assuming df is your DataFrame and 'CHANGE DESCRIPTION' is the column to translate.\n",
        "translator = Translator()\n",
        "\n",
        "def translate_column(df, column_name):\n",
        "    # Handle potential errors during translation\n",
        "    def translate_text(text):\n",
        "      return translator.translate(str(text), dest='en').text  # Ensure text is a string\n",
        "\n",
        "    df[column_name + '_translated'] = df[column_name].apply(translate_text)\n",
        "    return df"
      ],
      "metadata": {
        "id": "X5qYUpPD4WMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_column(df,'CHANGE DESCRIPTION')"
      ],
      "metadata": {
        "id": "5AyTuMRc7eiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''''\n",
        "\n",
        "# prompt: divide df into many parts. apply translate_column(df, 'CHANGE DESCRIPTION') to each and merge all df\n",
        "\n",
        "\n",
        "# Divide df into smaller parts (e.g., chunks of 100 rows)\n",
        "chunk_size = 100\n",
        "translated_dfs = []\n",
        "\n",
        "for i in range(0, len(df), chunk_size):\n",
        "  chunk = df[i:i + chunk_size].copy()\n",
        "  chunk = translate_column(chunk, 'CHANGE DESCRIPTION')\n",
        "  translated_dfs.append(chunk)\n",
        "\n",
        "# Concatenate the translated chunks back into a single DataFrame\n",
        "df = pd.concat(translated_dfs, ignore_index=True)\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Lr4v3wDZ3CMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "W0oTPW6RCo7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6KB1hXnm8hRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXq6oF0V9Cvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfcKFN969CsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "izedAhyD9CpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_SehUez69Clt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "!pip install BHDataAnalysis\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "2BtF-6EnCo7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "from BHDataAnalysis import featureEngineeringFile\n",
        "\n",
        "!pip show BHDataAnalysis\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "3IKRWLyICo7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########          ALMIGHTY PROCESS METHOD\n",
        "\n",
        "\n",
        "import os\n",
        "import nltk\n",
        "import spacy\n",
        "\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "\n",
        "def completePreprocessMethod(str):\n",
        "\n",
        "\n",
        "\n",
        "  #Tokenization\n",
        "  #==================\n",
        "  token_doc=nlp(str.lower())\n",
        "  token_array=[]\n",
        "\n",
        "  for token in token_doc:\n",
        "    token_array.append(token.text)\n",
        "    token_string=' '.join(token_array)\n",
        "\n",
        "  print(\"\\n After Tokenization-------->\\n\",token_string)\n",
        "\n",
        "\n",
        "  #remove stopwords and punct and lemmatize\n",
        "  #==================\n",
        "  from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "  stoppunclemma_doc=nlp(token_string)\n",
        "  stoppunclemma_array=[]\n",
        "\n",
        "  for token in stoppunclemma_doc:\n",
        "\n",
        "    if not (token.is_stop or token.is_punct):\n",
        "      stoppunclemma_array.append(token.lemma_)\n",
        "\n",
        "  stoppunclemma_string=' '.join(stoppunclemma_array)\n",
        "\n",
        "  print(\"\\n After removing stopwords and punctuations and lemmatizing-------->\\n\",stoppunclemma_string)\n",
        "\n",
        "\n",
        "\n",
        "  '''\n",
        "  #stemming\n",
        "  #==================\n",
        "  words=stoppunclemma_array\n",
        "  from nltk.stem import PorterStemmer\n",
        "  stemmer=PorterStemmer()\n",
        "  stemmArray=[]\n",
        "\n",
        "  for i in words:\n",
        "    stemmArray.append(stemmer.stem(i))\n",
        "\n",
        "  string_stemm = ' '.join(stemmArray)\n",
        "  print(\"\\nAfter stemming-------->\\n\",string_stemm)\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "  '''\n",
        "  #lemma\n",
        "  #==================\n",
        "  lemma_doc=nlp(string_stemm)\n",
        "\n",
        "  lemmaArray=[]\n",
        "\n",
        "  for i in lemma_doc:\n",
        "    lemmaArray.append(i.lemma_)\n",
        "\n",
        "  string_lemma = ' '.join(lemmaArray)\n",
        "  print(\"\\nafter lemmatization-------->\\n\",string_lemma)\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "  final_string=stoppunclemma_string\n",
        "\n",
        "  print(\"Final string\\n\")\n",
        "\n",
        "  return final_string\n",
        "\n"
      ],
      "metadata": {
        "id": "TLblKEdq-AKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def almightyPreprocessMethod(anything):\n",
        "  if isinstance(anything,str):\n",
        "    if anything.endswith('.txt'):\n",
        "      #text file as param\n",
        "      with open(anything) as f:\n",
        "        text=f.readlines()\n",
        "\n",
        "      proper_text = ' '.join(text)\n",
        "\n",
        "      final_string=complete_preprocess(proper_text)\n",
        "      return final_string\n",
        "\n",
        "\n",
        "    else:\n",
        "      #string as param\n",
        "      final_string=completePreprocessMethod(anything)\n",
        "      return final_string\n",
        "\n",
        "  elif isinstance(anything,list):\n",
        "    #list/array as param\n",
        "    tokenized_string=' '.join(anything)\n",
        "\n",
        "    final_string=completePreprocessMethod(tokenized_string)\n",
        "    return final_string\n",
        "\n",
        "  else:\n",
        "    return \"Invalid param passed\""
      ],
      "metadata": {
        "id": "0p9GlZgT-Hp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CHANGE DESCRIPTION_translated_preprocessed']=df['CHANGE DESCRIPTION_translated'].apply(lambda x: almightyPreprocessMethod(x))\n"
      ],
      "metadata": {
        "id": "UEre_7R_Co7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "tl2Z-zBmCo7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_QaJUgwCo7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "plYcMw2VQ8A2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dZpq8jH4Q78-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVX8R9-JQ747"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new col to find docs in change description"
      ],
      "metadata": {
        "id": "L4HAj1tfCo7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "Um1mcJlJSLk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['CHANGE DESCRIPTION_translated_preprocessed']=df['CHANGE DESCRIPTION_translated_preprocessed'].astype(str)"
      ],
      "metadata": {
        "id": "VOiNdtZZSQqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if a word which contains any numericals in df[CHANGE DESCRIPTION_translated], get ONLY that values and add it in new column 'Doc_name_from_description'. if it is only alphabets, dont add it\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_doc_numbers(text):\n",
        "    # Regular expression to find numerical sequences (potential document numbers)\n",
        "    doc_numbers = re.findall(r'\\w+\\d[\\w\\d]+', text)\n",
        "    return ','.join(doc_numbers) if doc_numbers else ''\n",
        "\n",
        "df['Docs_in_CHANGE DESCRIPTION'] = df['CHANGE DESCRIPTION_translated_preprocessed'].apply(extract_doc_numbers)\n"
      ],
      "metadata": {
        "id": "yTIxkn42Co7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "a0UGhuwjSZaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total 54 rows has no doc mentioned in Change description.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df['Docs_in_CHANGE DESCRIPTION'].eq('').sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "fj9ZEaJBCo7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "89RTd6TYCo7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from this we can see each change description is UNIQUE.  need to do cosine similarity | or analyse based on only ADD component, remove component etc\n",
        "\n",
        "df['CHANGE DESCRIPTION_translated'].value_counts()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4yLA9Ba6Co7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: find count of every word in  df[CHANGE DESCRIPTION_translated_preprocessed]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.lower().split()\n",
        "    return Counter(words)\n",
        "\n",
        "word_counts = df['CHANGE DESCRIPTION_translated_preprocessed'].apply(count_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_word_counts = Counter()\n",
        "for counts in word_counts:\n",
        "    total_word_counts.update(counts)\n",
        "\n",
        "total_word_counts"
      ],
      "metadata": {
        "id": "EV5lu1a7Co7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a method which takes in a word and returns total_word_counts value\n",
        "\n",
        "def search_change_description(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_word_counts[word]"
      ],
      "metadata": {
        "id": "9dqgGRowAcdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_change_description('siemens')"
      ],
      "metadata": {
        "id": "2s9ZFHzkAuNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  a method which takes a word as input. check if it is present in df[CHANGE DESCRIPTION_translated_preprocessed], if yes, then return entire row\n",
        "\n",
        "def find_word_in_change_description(word,change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['CHANGE DESCRIPTION_translated_preprocessed'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','CHANGE DESCRIPTION_translated']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "y6VY_mwNDyyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "find_word_in_change_description(\"siemens\" ,\"CIS/CIS+FFF&P\")\n"
      ],
      "metadata": {
        "id": "nVSnQTEBD8Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPACTED ITEM DESCRIPTION"
      ],
      "metadata": {
        "id": "XqRD-jR5_AXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "9m5ftpix_D9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['IMPACTED ITEM DESCRIPTION_preprocessed']=df['IMPACTED ITEM DESCRIPTION'].apply(lambda x: almightyPreprocessMethod(x))\n"
      ],
      "metadata": {
        "id": "m9OkJqyiAaWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "NH6NLBR8AhrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.lower().split()\n",
        "    return Counter(words)\n",
        "\n",
        "impacted_item_word_counts = df['IMPACTED ITEM DESCRIPTION_preprocessed'].apply(count_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_impacted_item_word_counts = Counter()\n",
        "for counts in impacted_item_word_counts:\n",
        "    total_impacted_item_word_counts.update(counts)\n",
        "\n",
        "total_impacted_item_word_counts"
      ],
      "metadata": {
        "id": "jbY00u-bAjnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_impacted_item(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_impacted_item_word_counts[word]"
      ],
      "metadata": {
        "id": "MR4PslC_GTO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_impacted_item('valve')"
      ],
      "metadata": {
        "id": "TEri_fKXIaT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIO_jgTxJ1n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_in_impacted_item(word, change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['IMPACTED ITEM DESCRIPTION_preprocessed'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','IMPACTEDITEM','IMPACTED ITEM DESCRIPTION_preprocessed']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "HBn2ZcXwJ2Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word_in_impacted_item(\"flux\", \"FFF&P ONLY\")"
      ],
      "metadata": {
        "id": "rBE2XOZxKgrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNMGj9I-vHWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save csv | final csv after preprocessing"
      ],
      "metadata": {
        "id": "CHRL3PGNwLyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# : save above df\n",
        "\n",
        "from google.colab import files\n",
        "df.to_csv('df_final.csv')\n",
        "files.download('df_final.csv')"
      ],
      "metadata": {
        "id": "lT_Mi07-wRXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.read_csv('/content/df_final.csv')"
      ],
      "metadata": {
        "id": "p9mxtM6lwZb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search methods"
      ],
      "metadata": {
        "id": "rPsjBUcsvIBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df2=pd.read_csv('/content/df_final.csv')"
      ],
      "metadata": {
        "id": "qYNNDmNlvLiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: make all col in df to str\n",
        "\n",
        "for col in df2.columns:\n",
        "  df2[col] = df2[col].astype(str)"
      ],
      "metadata": {
        "id": "JQ6XlVjExXbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['CHANGE DESCRIPTION']=df2['CHANGE DESCRIPTION'].astype(str)"
      ],
      "metadata": {
        "id": "vpEIRZFAxhjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "HUXo4qlIxNxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_change_category_words(text):\n",
        "    words = text.lower().split(',')\n",
        "    return Counter(words)\n",
        "\n",
        "change_category_word_counts = df['CHANGE_CATEGORY'].apply(count_change_category_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_change_category_word_counts = Counter()\n",
        "for counts in change_category_word_counts:\n",
        "    total_change_category_word_counts.update(counts)\n",
        "\n",
        "total_change_category_word_counts"
      ],
      "metadata": {
        "id": "DOC0JR_YwA5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_change_category(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_change_category_word_counts[word]"
      ],
      "metadata": {
        "id": "jXWGMRpcwA5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_change_category(\"move component\")"
      ],
      "metadata": {
        "id": "Omn8Wz4BwA5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_in_change_category(word, change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['CHANGE_CATEGORY'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','MATERIAL_CATEGORY']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "gUXFWAI3wA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word_in_change_category(\"move component\", \"FFF&P ONLY\")"
      ],
      "metadata": {
        "id": "zeBu23lrwA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def count_material_words(text):\n",
        "    words = text.lower().split(',')\n",
        "    return Counter(words)\n",
        "\n",
        "material_category_word_counts = df['MATERIAL_CATEGORY'].apply(count_material_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_material_category_word_counts = Counter()\n",
        "for counts in material_category_word_counts:\n",
        "    total_material_category_word_counts.update(counts)\n",
        "\n",
        "total_material_category_word_counts"
      ],
      "metadata": {
        "id": "hDX-kwiRwA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_material_category(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_material_category_word_counts[word]"
      ],
      "metadata": {
        "id": "wyad29bnwA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_material_category(\"gearbox\")"
      ],
      "metadata": {
        "id": "FO2Qn7GawA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_in_material_category(word, change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['MATERIAL_CATEGORY'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','MATERIAL_CATEGORY']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "atmsYOZZwA5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word_in_material_category(\"gearbox\", \"FFF&P ONLY\")"
      ],
      "metadata": {
        "id": "vfdv26gwwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: find count of every word in  df[CHANGE DESCRIPTION_translated_preprocessed]\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.lower().split()\n",
        "    return Counter(words)\n",
        "\n",
        "word_counts = df['CHANGE DESCRIPTION_translated_preprocessed'].apply(count_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_word_counts = Counter()\n",
        "for counts in word_counts:\n",
        "    total_word_counts.update(counts)\n",
        "\n",
        "total_word_counts"
      ],
      "metadata": {
        "id": "l-BZjeHHwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a method which takes in a word and returns total_word_counts value\n",
        "\n",
        "def search_change_description(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_word_counts[word]"
      ],
      "metadata": {
        "id": "eqOby_PHwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_change_description('siemens')"
      ],
      "metadata": {
        "id": "uaYWTDJSwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  a method which takes a word as input. check if it is present in df[CHANGE DESCRIPTION_translated_preprocessed], if yes, then return entire row\n",
        "\n",
        "def find_word_in_change_description(word,change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['CHANGE DESCRIPTION_translated_preprocessed'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','CHANGE DESCRIPTION_translated']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "2B6UN6VowA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "find_word_in_change_description(\"siemens\" ,\"CIS/CIS+FFF&P\")\n"
      ],
      "metadata": {
        "id": "7LlQtJCywA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def count_words(text):\n",
        "    words = text.lower().split()\n",
        "    return Counter(words)\n",
        "\n",
        "impacted_item_word_counts = df['IMPACTED ITEM DESCRIPTION_preprocessed'].apply(count_words)\n",
        "\n",
        "# Combine word counts from all rows\n",
        "total_impacted_item_word_counts = Counter()\n",
        "for counts in impacted_item_word_counts:\n",
        "    total_impacted_item_word_counts.update(counts)\n",
        "\n",
        "total_impacted_item_word_counts"
      ],
      "metadata": {
        "id": "4Sl-RyJzwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_impacted_item(word):\n",
        "  word = word.lower()\n",
        "\n",
        "  return total_impacted_item_word_counts[word]"
      ],
      "metadata": {
        "id": "PAtTzrbBwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_impacted_item('valve')"
      ],
      "metadata": {
        "id": "Zc-3ZTcjwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_word_in_impacted_item(word, change_type):\n",
        "  word = word.lower()\n",
        "\n",
        "\n",
        "  matching_rows = df[(df['IMPACTED ITEM DESCRIPTION_preprocessed'].str.contains(word, case=False, na=False)) & (df['CHANGE_TYPE'] == change_type)]\n",
        "\n",
        "  if not matching_rows.empty:\n",
        "    return matching_rows[['ECR_CODE', 'COSTING_PROJECTS_new_col','CHANGE_CATEGORY','IMPACTEDITEM','IMPACTED ITEM DESCRIPTION_preprocessed']]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "O3XVPKnPwA5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_word_in_impacted_item(\"flux\", \"FFF&P ONLY\")"
      ],
      "metadata": {
        "id": "_zEIzmhPwA5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data for training | all transformation, encoding, etc"
      ],
      "metadata": {
        "id": "CSyLkQgQMXE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# label encode SOURCE OF CHANGE\n",
        "\n",
        "#label encode these\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le_source_of_change = LabelEncoder()\n",
        "df['SOURCE OF CHANGE'] = le_source_of_change.fit_transform(df['SOURCE OF CHANGE'])\n",
        "\n",
        "le_source_of_change_classes = dict(zip(le_source_of_change.classes_, le_source_of_change.transform(le_source_of_change.classes_)))\n",
        "\n",
        "le_source_of_change_classes"
      ],
      "metadata": {
        "id": "XiUyJL6iMfP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label encode REASON DESC\n",
        "\n",
        "le_reason_desc = LabelEncoder()\n",
        "df['REASON_DESC'] = le_reason_desc.fit_transform(df['REASON_DESC'])\n",
        "\n",
        "le_reason_desc_classes = dict(zip(le_reason_desc.classes_, le_reason_desc.transform(le_reason_desc.classes_)))\n",
        "\n",
        "le_reason_desc_classes"
      ],
      "metadata": {
        "id": "-VGURYuDNPpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#multilabel binarizer for CHANGE_CATEGORY col\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "df['CHANGE_CATEGORY']=df['CHANGE_CATEGORY'].astype(str)\n",
        "df['CHANGE_CATEGORY'] = df['CHANGE_CATEGORY'].apply(lambda x: x.split(','))\n",
        "\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "change_category_encoded = pd.DataFrame(mlb.fit_transform(df['CHANGE_CATEGORY']),\n",
        "                                       columns=mlb.classes_,\n",
        "                                       index=df.index)\n",
        "\n",
        "# Concatenate the original data with the encoded columns\n",
        "df = pd.concat([df, change_category_encoded], axis=1)\n",
        "\n",
        "# Drop the original 'CHANGE_CATEGORY' column if no longer needed\n",
        "df.drop(columns=['CHANGE_CATEGORY'], inplace=True)"
      ],
      "metadata": {
        "id": "2qtNszfRNbup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ADD COMPONENT -> \", len(df[df['ADD COMPONENT']==1]))\n",
        "\n",
        "print(\"CHANGE QTY -> \", len(df[df['CHANGE QTY']==1]))\n",
        "\n",
        "print(\"COSTOUT/SMI -> \", len(df[df['COSTOUT/SMI']==1]))\n",
        "\n",
        "print(\"DOCUMENT -> \", len(df[df['DOCUMENT']==1]))\n",
        "\n",
        "print(\"MOVE COMPONENT -> \", len(df[df['MOVE COMPONENT']==1]))\n",
        "\n",
        "print(\"NEW PRODUCT DEVELOPMENT (NPD) -> \", len(df[df['NEW PRODUCT DEVELOPMENT (NPD)']==1]))\n",
        "\n",
        "print(\"PCB CATEGORY -> \", len(df[df['PCB CATEGORY']==1]))\n",
        "\n",
        "print(\"REMOVE COMPONENT -> \", len(df[df['REMOVE COMPONENT']==1]))\n"
      ],
      "metadata": {
        "id": "481LWLTBNqpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for the bar chart (replace with your actual data)\n",
        "categories = ['ADD COMPONENT', 'CHANGE QTY', 'COSTOUT/SMI', 'DOCUMENT', 'MOVE COMPONENT', 'NEW PRODUCT DEVELOPMENT (NPD)', 'PCB CATEGORY', 'REMOVE COMPONENT']\n",
        "counts = [len(df[df['ADD COMPONENT']==1]), len(df[df['CHANGE QTY']==1]), len(df[df['COSTOUT/SMI']==1]), len(df[df['DOCUMENT']==1]), len(df[df['MOVE COMPONENT']==1]), len(df[df['NEW PRODUCT DEVELOPMENT (NPD)']==1]), len(df[df['PCB CATEGORY']==1]), len(df[df['REMOVE COMPONENT']==1])]\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(categories, counts, color='purple')\n",
        "plt.xlabel(\"Change Categories\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Count of Different Change Categories\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Add value labels on top of each bar\n",
        "for bar, count in zip(bars, counts):\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(count), ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7OML0Fn3Nvkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try doing multilabel binarizer or\n",
        "\n",
        "\n",
        "#multilabel binarizer for MATERIAL_CATEGORY col\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "df['MATERIAL_CATEGORY']=df['MATERIAL_CATEGORY'].astype(str)\n",
        "df['MATERIAL_CATEGORY'] = df['MATERIAL_CATEGORY'].apply(lambda x: x.split(','))\n",
        "\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "material_category_encoded = pd.DataFrame(mlb.fit_transform(df['MATERIAL_CATEGORY']),\n",
        "                                       columns=mlb.classes_,\n",
        "                                       index=df.index)\n",
        "\n",
        "# Concatenate the original data with the encoded columns\n",
        "df = pd.concat([df, material_category_encoded], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "#label encoder\n",
        "le_material_category = LabelEncoder()\n",
        "df['MATERIAL_CATEGORY'] = le_material_category.fit_transform(df['MATERIAL_CATEGORY'])\n",
        "\n",
        "le_material_category_classes = dict(zip(le_material_category.classes_, le_material_category.transform(le_material_category.classes_)))\n",
        "\n",
        "le_material_category_classes\n",
        "'''"
      ],
      "metadata": {
        "id": "WdNRiGB9N99p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AUXILIARY BASEPLATE -> \", len(df[df['AUXILIARY BASEPLATE']==1]))\n",
        "\n",
        "print(\"BASEPLATE -> \", len(df[df['BASEPLATE']==1]))\n",
        "\n",
        "print(\"CABLES -> \", len(df[df['CABLES']==1]))\n",
        "\n",
        "print(\"CONTROL CABINET -> \", len(df[df['CONTROL CABINET']==1]))\n",
        "\n",
        "print(\"COUPLING -> \", len(df[df['COUPLING']==1]))\n",
        "\n",
        "print(\"COUPLING GUARD -> \", len(df[df['COUPLING GUARD']==1]))\n",
        "\n",
        "print(\"DRY GAS SEAL PANEL/TREATMENT/BOOSTER -> \", len(df[df['DRY GAS SEAL PANEL/TREATMENT/BOOSTER']==1]))\n",
        "\n",
        "print(\"DUCTS -> \", len(df[df['DUCTS']==1]))\n",
        "\n",
        "print(\"ENCLOSURE -> \", len(df[df['ENCLOSURE']==1]))\n",
        "\n",
        "print(\"EQUIPMENT/MATERIAL FULL SUPPLY -> \", len(df[df['EQUIPMENT/MATERIAL FULL SUPPLY']==1]))\n",
        "\n",
        "\n",
        "\n",
        "print(\"F2F -> \", len(df[df['F2F']==1]))\n",
        "\n",
        "print(\"FILTER HOUSE -> \", len(df[df['FILTER HOUSE']==1]))\n",
        "\n",
        "print(\"GEARBOX -> \", len(df[df['GEARBOX']==1]))\n",
        "\n",
        "#print(\"GEARBOX RAW -> \", len(df[df['GEARBOX RAW']==1]))\n",
        "\n",
        "print(\"INSTRUMENTATION -> \", len(df[df['INSTRUMENTATION']==1]))\n",
        "\n",
        "print(\"INTERCONNECTING PIPING AND SUPPORTS -> \", len(df[df['INTERCONNECTING PIPING AND SUPPORTS']==1]))\n",
        "\n",
        "print(\"LOW VOLTAGE MOTOR -> \", len(df[df['LOW VOLTAGE MOTOR']==1]))\n",
        "\n",
        "print(\"LUBE OIL CONSOLE -> \", len(df[df['LUBE OIL CONSOLE']==1]))\n",
        "\n",
        "print(\"MAIN MOTOR/GENERATOR -> \", len(df[df['MAIN MOTOR/GENERATOR']==1]))\n",
        "\n",
        "print(\"MCC -> \", len(df[df['MCC']==1]))\n",
        "\n",
        "\n",
        "\n",
        "print(\"OTHER -> \", len(df[df['OTHER']==1]))\n",
        "\n",
        "print(\"PIPINGS & SUPPORTS -> \", len(df[df['PIPINGS & SUPPORTS']==1]))\n",
        "\n",
        "print(\"PUMP FOR AUXILIARIES -> \", len(df[df['PUMP FOR AUXILIARIES']==1]))\n",
        "\n",
        "print(\"SHAFT LINE-> \", len(df[df['SHAFT LINE']==1]))\n",
        "\n",
        "print(\"SPARE PARTS -> \", len(df[df['SPARE PARTS']==1]))\n",
        "\n",
        "print(\"SPECIAL TOOLS -> \", len(df[df['SPECIAL TOOLS']==1]))\n",
        "\n",
        "print(\"STEEL STRUCTURES -> \", len(df[df['STEEL STRUCTURES']==1]))\n",
        "\n",
        "print(\"UCP/CONTROL SYSTEM -> \", len(df[df['UCP/CONTROL SYSTEM']==1]))\n",
        "\n",
        "print(\"VALVES -> \", len(df[df['VALVES']==1]))\n",
        "\n",
        "print(\"MCC -> \", len(df[df['MCC']==1]))\n"
      ],
      "metadata": {
        "id": "nSV2qeanOLkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  enter a JobNo. and a col (add component, remove, anything)  based on this it will tell which Material category is affected along with its ECR_CODE\n",
        "\n",
        "def get_material_categories(costing_projects_value, col):\n",
        "    \"\"\"\n",
        "    This method takes in 'COSTING_PROJECTS_new_col' value and 'ADD COMPONENT' value\n",
        "    and returns all material categories associated with the given criteria along with ECR_CODE.\n",
        "    \"\"\"\n",
        "    # Filter the DataFrame based on the provided criteria\n",
        "    filtered_df = df[(df['COSTING_PROJECTS_new_col'] == costing_projects_value) & (df[col] == 1)]\n",
        "\n",
        "    # Extract the material categories and ECR_CODE from the filtered data\n",
        "    if not filtered_df.empty:\n",
        "        for index, row in filtered_df.iterrows():\n",
        "            print(f\"ECR_CODE: {row['ECR_CODE']}, Material Category: {row['MATERIAL_CATEGORY']}\")\n",
        "    else:\n",
        "        print(\"No material categories found for given criteria\")\n"
      ],
      "metadata": {
        "id": "gVwKdJbdPgoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_material_categories(\"315529\", 'REMOVE COMPONENT')"
      ],
      "metadata": {
        "id": "_QxO6gZuPke4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: translate df[column]  to english\n",
        "\n",
        "def translate_column(df, column_name):\n",
        "  \"\"\"Translates the specified column in a DataFrame to English.\n",
        "\n",
        "  Args:\n",
        "      df: The input DataFrame.\n",
        "      column_name: The name of the column to translate.\n",
        "\n",
        "  Returns:\n",
        "      The DataFrame with the translated column added.\n",
        "  \"\"\"\n",
        "  translator = Translator()\n",
        "  df[column_name + '_translated'] = df[column_name].astype(str).apply(lambda x: translator.translate(x, dest='en').text)\n",
        "  return df\n",
        "\n",
        "# Example usage (assuming your DataFrame is named 'df' and the column to translate is 'column'):\n",
        "df = translate_column(df, 'DESCRIPTION')"
      ],
      "metadata": {
        "id": "qr5GgG2ws1KA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}