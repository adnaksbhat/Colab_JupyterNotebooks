{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNilADCj393jh7DzDANQFDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaksbhat/Colab_JupyterNotebooks/blob/main/Chatgpt_codes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Analysis of ECN/ECR"
      ],
      "metadata": {
        "id": "43MSJG0UUSPM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmYHMcfzUWom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vik6kEqdTrWi",
        "outputId": "3b12d799-0f97-46f5-9ac9-b9c57ec1e4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ],
      "source": [
        "print(\"hi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i have csv files with columns 'RefId' , 'System name', 'part name', 'changes' , 'ebom' , 'comments'.\n",
        "This file is related to changes done in middle of a work\n",
        "\n",
        "help me preprocess this file and make an analysis on how to notify in prior what changes may occur beforehand"
      ],
      "metadata": {
        "id": "UpVm7rvIT5ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To preprocess this CSV file and analyze the data for predicting potential changes beforehand, follow these steps:\n",
        "\n",
        "### Step 1: Data Cleaning\n",
        "1. **Handle Missing Values**:\n",
        "   - Identify missing values in each column.\n",
        "   - For columns like 'RefId' and 'part name', missing values may be problematic, so consider filling them based on similar entries or removing such rows.\n",
        "   - For 'comments' or 'changes', fill in with default text like \"No comments\" if missing.\n",
        "\n",
        "2. **Standardize Text**:\n",
        "   - Convert 'System name', 'part name', and 'changes' to lowercase for consistency.\n",
        "   - Remove special characters, extra spaces, and typos.\n",
        "\n",
        "3. **Remove Duplicates**:\n",
        "   - Check for and remove any duplicate entries based on 'RefId' or a combination of relevant columns.\n",
        "\n",
        "### Step 2: Feature Engineering\n",
        "1. **Create New Features**:\n",
        "   - **Change Type**: Categorize changes (e.g., \"minor update,\" \"major redesign\") based on keywords in the 'changes' column.\n",
        "   - **System/Part Frequency**: Calculate how frequently each system or part has undergone changes.\n",
        "   - **Time Since Last Change**: If you have timestamps, compute the duration between the current and previous changes.\n",
        "\n",
        "2. **Text Analysis for 'comments' and 'changes'**:\n",
        "   - Perform sentiment analysis or keyword extraction to see if certain terms or sentiment patterns correlate with specific change types.\n",
        "\n",
        "### Step 3: Analysis and Prediction\n",
        "1. **Exploratory Data Analysis (EDA)**:\n",
        "   - Visualize change frequency over time (e.g., number of changes per month).\n",
        "   - Identify patterns linking certain systems or parts to frequent changes.\n",
        "   - Use correlation analysis to find relationships between features.\n",
        "\n",
        "2. **Predictive Modeling**:\n",
        "   - **Classification Models**: Predict the likelihood of specific changes occurring based on features.\n",
        "   - **Time Series Analysis**: If you have a timeline, predict future changes using models like ARIMA or LSTM.\n",
        "\n",
        "3. **Anomaly Detection**:\n",
        "   - Use anomaly detection algorithms to flag unusual changes that may indicate unexpected issues.\n",
        "\n",
        "These steps will help preprocess the data and build a foundation for predictive analysis. Let me know if you need help with any of these tasks!"
      ],
      "metadata": {
        "id": "O2OIlfzBUNh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a complete code example that follows the steps for preprocessing the data, performing exploratory data analysis (EDA), and building a basic predictive model using Python libraries like `pandas`, `scikit-learn`, and `matplotlib`. This code assumes you have the necessary libraries installed.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "# Step 1: Data Loading\n",
        "df = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Step 2: Data Cleaning\n",
        "# 2.1 Handle Missing Values\n",
        "df.fillna({'comments': 'No comments', 'changes': 'No change'}, inplace=True)\n",
        "df.dropna(subset=['RefId', 'part name'], inplace=True)\n",
        "\n",
        "# 2.2 Standardize Text\n",
        "df['System name'] = df['System name'].str.lower().str.strip()\n",
        "df['part name'] = df['part name'].str.lower().str.strip()\n",
        "df['changes'] = df['changes'].str.lower().str.strip()\n",
        "\n",
        "# 2.3 Remove Duplicates\n",
        "df.drop_duplicates(subset=['RefId'], inplace=True)\n",
        "\n",
        "# Step 3: Feature Engineering\n",
        "# 3.1 Change Type Classification\n",
        "def categorize_change(change_text):\n",
        "    if \"redesign\" in change_text:\n",
        "        return \"major redesign\"\n",
        "    elif \"update\" in change_text:\n",
        "        return \"minor update\"\n",
        "    else:\n",
        "        return \"other\"\n",
        "\n",
        "df['change_type'] = df['changes'].apply(categorize_change)\n",
        "\n",
        "# 3.2 System/Part Frequency\n",
        "df['system_frequency'] = df.groupby('System name')['System name'].transform('count')\n",
        "df['part_frequency'] = df.groupby('part name')['part name'].transform('count')\n",
        "\n",
        "# Step 4: Exploratory Data Analysis (EDA)\n",
        "# 4.1 Plotting the Distribution of Change Types\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='change_type', data=df)\n",
        "plt.title('Distribution of Change Types')\n",
        "plt.show()\n",
        "\n",
        "# 4.2 Heatmap of Correlation Matrix\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap='viridis')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 5: Predictive Modeling\n",
        "# 5.1 Label Encoding for Classification\n",
        "label_encoder = LabelEncoder()\n",
        "df['change_type_encoded'] = label_encoder.fit_transform(df['change_type'])\n",
        "\n",
        "# 5.2 Selecting Features for Prediction\n",
        "features = ['system_frequency', 'part_frequency']\n",
        "X = df[features]\n",
        "y = df['change_type_encoded']\n",
        "\n",
        "# 5.3 Splitting the Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5.4 Training a Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# 5.5 Making Predictions and Evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# Step 6: Anomaly Detection\n",
        "# 6.1 Using Isolation Forest for Anomaly Detection\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "df['anomaly_score'] = iso_forest.fit_predict(X)\n",
        "\n",
        "# Visualizing Anomalies\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='system_frequency', y='part_frequency', hue='anomaly_score', data=df, palette='coolwarm')\n",
        "plt.title('Anomaly Detection')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "1. **Data Loading & Cleaning**: Reads the CSV, handles missing values, standardizes text, and removes duplicates.\n",
        "2. **Feature Engineering**: Categorizes the 'changes' column, calculates the frequency of systems and parts, and adds these as new features.\n",
        "3. **EDA**: Uses plots for the distribution of change types and a heatmap to show correlations.\n",
        "4. **Predictive Modeling**: Implements a Random Forest classifier for predicting change types.\n",
        "5. **Anomaly Detection**: Applies Isolation Forest to detect unusual changes.\n",
        "\n",
        "Make sure to replace `'your_file.csv'` with the path to your actual CSV file. Let me know if you need more customization or help with a specific part!"
      ],
      "metadata": {
        "id": "N0chFzJGT95X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D44jADz3UCXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}